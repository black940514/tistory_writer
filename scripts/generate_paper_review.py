"""
ë…¼ë¬¸ ë¦¬ë·° ìƒì„± ë° ê´€ë¦¬ í”„ë¡œê·¸ë¨
ë…¼ë¬¸ëª…, arXiv ì£¼ì†Œ ë“±ì„ ì…ë ¥ë°›ì•„ MD íŒŒì¼ ìƒì„± ë° ì‘ì„± ì´ë ¥ ê´€ë¦¬
"""
import sys
import yaml
import json
import logging
import argparse
from pathlib import Path
from typing import Dict, Optional, List
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
from scripts.get_project_root import get_project_root
project_root = get_project_root()

# src ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(project_root))

from scripts.generate_single_output import (
    generate_single_output,
    extract_arxiv_id,
    sanitize_filename
)

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = project_root / 'data'
log_dir.mkdir(exist_ok=True)

# ì‘ì„± ì´ë ¥ íŒŒì¼
REVIEW_HISTORY_FILE = project_root / 'data' / 'review_history.json'

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'paper_review_manager.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ReviewHistoryManager:
    """ì‘ì„±í•œ ë…¼ë¬¸ ë¦¬ë·° ì´ë ¥ ê´€ë¦¬"""
    
    def __init__(self, history_file: Path = REVIEW_HISTORY_FILE):
        self.history_file = history_file
        self.history_file.parent.mkdir(parents=True, exist_ok=True)  # ë””ë ‰í† ë¦¬ ìƒì„±
        self.history = self._load_history()
    
    def _load_history(self) -> List[Dict]:
        """ì´ë ¥ íŒŒì¼ ë¡œë“œ"""
        if not self.history_file.exists():
            return []
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('reviews', [])
        except Exception as e:
            logger.error(f"ì´ë ¥ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def _save_history(self):
        """ì´ë ¥ íŒŒì¼ ì €ì¥"""
        try:
            data = {
                'reviews': self.history,
                'last_updated': datetime.now().isoformat(),
                'total_count': len(self.history)
            }
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ì´ë ¥ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def add_review(self, paper_info: Dict, output_file: str):
        """ì‘ì„± ì´ë ¥ ì¶”ê°€"""
        review_entry = {
            'paper_title': paper_info.get('title', 'N/A'),
            'arxiv_id': paper_info.get('arxiv_id'),
            'url': paper_info.get('url'),
            'authors': paper_info.get('authors', []),
            'year': paper_info.get('year'),
            'output_file': output_file,
            'created_at': datetime.now().isoformat()
        }
        
        # ì¤‘ë³µ ì²´í¬
        if self.is_duplicate(paper_info):
            logger.warning(f"ì´ë¯¸ ì‘ì„±ëœ ë…¼ë¬¸ì…ë‹ˆë‹¤: {paper_info.get('title', 'N/A')}")
            return False
        
        self.history.append(review_entry)
        self._save_history()
        logger.info(f"ì‘ì„± ì´ë ¥ ì¶”ê°€ë¨: {paper_info.get('title', 'N/A')}")
        return True
    
    def is_duplicate(self, paper_info: Dict) -> bool:
        """ì¤‘ë³µ ì²´í¬"""
        title = paper_info.get('title', '').lower().strip()
        arxiv_id = paper_info.get('arxiv_id')
        url = paper_info.get('url')
        
        for review in self.history:
            # ì œëª©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
            if review.get('paper_title', '').lower().strip() == title:
                return True
            
            # arXiv IDë¡œ ì¤‘ë³µ ì²´í¬
            if arxiv_id and review.get('arxiv_id') == arxiv_id:
                return True
            
            # URLë¡œ ì¤‘ë³µ ì²´í¬
            if url and review.get('url') == url:
                return True
        
        return False
    
    def list_reviews(self, limit: Optional[int] = None) -> List[Dict]:
        """ì‘ì„± ì´ë ¥ ëª©ë¡ ë°˜í™˜ (ìµœì‹ ìˆœ)"""
        reviews = sorted(
            self.history,
            key=lambda x: x.get('created_at', ''),
            reverse=True
        )
        
        if limit:
            return reviews[:limit]
        return reviews
    
    def get_review_count(self) -> int:
        """ì‘ì„±í•œ ë¦¬ë·° ê°œìˆ˜"""
        return len(self.history)
    
    def search_reviews(self, query: str) -> List[Dict]:
        """ê²€ìƒ‰ (ì œëª©, ì €ì, arXiv ID)"""
        query_lower = query.lower()
        results = []
        
        for review in self.history:
            # ì œëª© ê²€ìƒ‰
            if query_lower in review.get('paper_title', '').lower():
                results.append(review)
                continue
            
            # arXiv ID ê²€ìƒ‰
            if review.get('arxiv_id') and query_lower in review.get('arxiv_id', '').lower():
                results.append(review)
                continue
            
            # ì €ì ê²€ìƒ‰
            authors = review.get('authors', [])
            if any(query_lower in author.lower() for author in authors):
                results.append(review)
                continue
        
        return results
    
    def remove_review(self, index: int) -> bool:
        """ì¸ë±ìŠ¤ë¡œ ë¦¬ë·° ì‚­ì œ"""
        if 0 <= index < len(self.history):
            removed = self.history.pop(index)
            self._save_history()
            logger.info(f"ë¦¬ë·° ì‚­ì œë¨: {removed.get('paper_title', 'N/A')}")
            return True
        return False


def create_review(input_str: str, config_path: Optional[str] = None, output_filename: Optional[str] = None) -> Optional[str]:
    """ë¦¬ë·° ìƒì„± ë° ì´ë ¥ ê´€ë¦¬"""
    history_manager = ReviewHistoryManager()
    
    # ë…¼ë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ì²´í¬ìš©)
    arxiv_id = extract_arxiv_id(input_str)
    paper_info_for_check = {'title': input_str, 'arxiv_id': arxiv_id, 'url': None}
    
    if arxiv_id:
        from scripts.generate_single_output import fetch_arxiv_paper_info
        arxiv_info = fetch_arxiv_paper_info(arxiv_id)
        if arxiv_info:
            paper_info_for_check = arxiv_info
    
    # ì¤‘ë³µ ì²´í¬
    if history_manager.is_duplicate(paper_info_for_check):
        print(f"âš ï¸  ì´ë¯¸ ì‘ì„±ëœ ë…¼ë¬¸ì…ë‹ˆë‹¤!")
        print(f"   ì œëª©: {paper_info_for_check.get('title', 'N/A')}")
        response = input("ê·¸ë˜ë„ ë‹¤ì‹œ ì‘ì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != 'y':
            return None
    
    # ë¦¬ë·° ìƒì„±
    filepath = generate_single_output(
        input_str=input_str,
        config_path=config_path,
        output_filename=output_filename
    )
    
    if filepath:
        # ì´ë ¥ ì¶”ê°€
        final_paper_info = paper_info_for_check.copy()
        if arxiv_id:
            final_paper_info['arxiv_id'] = arxiv_id
        
        history_manager.add_review(final_paper_info, filepath)
        print(f"\nâœ“ ë¦¬ë·° ìƒì„± ì™„ë£Œ: {filepath}")
        return filepath
    
    return None


def list_reviews(limit: Optional[int] = None, search: Optional[str] = None):
    """ì‘ì„± ì´ë ¥ ëª©ë¡ ì¶œë ¥"""
    history_manager = ReviewHistoryManager()
    
    if search:
        reviews = history_manager.search_reviews(search)
        print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼: '{search}' ({len(reviews)}ê°œ)")
    else:
        reviews = history_manager.list_reviews(limit=limit)
        total = history_manager.get_review_count()
        print(f"\nğŸ“ ì‘ì„±í•œ ë¦¬ë·° ëª©ë¡ (ì´ {total}ê°œ)")
    
    if not reviews:
        print("ì‘ì„±í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("-" * 80)
    for i, review in enumerate(reviews, 1):
        title = review.get('paper_title', 'N/A')
        arxiv_id = review.get('arxiv_id', 'N/A')
        year = review.get('year', 'N/A')
        created_at = review.get('created_at', '')
        
        if created_at:
            try:
                dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                created_str = dt.strftime('%Y-%m-%d %H:%M')
            except:
                created_str = created_at[:10]
        else:
            created_str = 'N/A'
        
        print(f"{i}. {title}")
        print(f"   arXiv: {arxiv_id} | Year: {year} | ì‘ì„±ì¼: {created_str}")
        print(f"   íŒŒì¼: {review.get('output_file', 'N/A')}")
        print()


def show_statistics():
    """í†µê³„ ì •ë³´ ì¶œë ¥"""
    history_manager = ReviewHistoryManager()
    reviews = history_manager.list_reviews()
    
    total = len(reviews)
    
    if total == 0:
        print("ì‘ì„±í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë…„ë„ë³„ í†µê³„
    year_counts = {}
    for review in reviews:
        year = review.get('year')
        if year:
            year_counts[year] = year_counts.get(year, 0) + 1
    
    print(f"\nğŸ“Š ì‘ì„± í†µê³„")
    print("=" * 50)
    print(f"ì´ ì‘ì„± ê°œìˆ˜: {total}ê°œ")
    
    if year_counts:
        print(f"\në…„ë„ë³„ ë¶„í¬:")
        for year in sorted(year_counts.keys(), reverse=True):
            print(f"  {year}ë…„: {year_counts[year]}ê°œ")
    
    # ìµœê·¼ ì‘ì„± (5ê°œ)
    print(f"\nìµœê·¼ ì‘ì„± (5ê°œ):")
    for i, review in enumerate(reviews[:5], 1):
        title = review.get('paper_title', 'N/A')
        created_at = review.get('created_at', '')
        if created_at:
            try:
                dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                created_str = dt.strftime('%Y-%m-%d')
            except:
                created_str = created_at[:10]
        else:
            created_str = 'N/A'
        
        print(f"  {i}. {title[:60]}... ({created_str})")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='ë…¼ë¬¸ ë¦¬ë·° ìƒì„± ë° ê´€ë¦¬ í”„ë¡œê·¸ë¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ìƒˆ ë¦¬ë·° ìƒì„±
  python scripts/generate_paper_review.py create "Attention Is All You Need"
  python scripts/generate_paper_review.py create "https://arxiv.org/abs/1706.03762"
  
  # ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
  python scripts/generate_paper_review.py list
  python scripts/generate_paper_review.py list --limit 10
  
  # ê²€ìƒ‰
  python scripts/generate_paper_review.py search "transformer"
  
  # í†µê³„
  python scripts/generate_paper_review.py stats
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # create ëª…ë ¹ì–´
    create_parser = subparsers.add_parser('create', help='ìƒˆ ë¦¬ë·° ìƒì„±')
    create_parser.add_argument('input', type=str, help='ë…¼ë¬¸ ì œëª© ë˜ëŠ” arXiv URL')
    create_parser.add_argument('--config', type=str, default=None, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    create_parser.add_argument('--output', type=str, default=None, help='ì¶œë ¥ íŒŒì¼ëª…')
    
    # list ëª…ë ¹ì–´
    list_parser = subparsers.add_parser('list', help='ì‘ì„±í•œ ë¦¬ë·° ëª©ë¡ ì¡°íšŒ')
    list_parser.add_argument('--limit', type=int, default=None, help='ì¶œë ¥ ê°œìˆ˜ ì œí•œ')
    
    # search ëª…ë ¹ì–´
    search_parser = subparsers.add_parser('search', help='ë¦¬ë·° ê²€ìƒ‰')
    search_parser.add_argument('query', type=str, help='ê²€ìƒ‰ì–´ (ì œëª©, ì €ì, arXiv ID)')
    
    # stats ëª…ë ¹ì–´
    stats_parser = subparsers.add_parser('stats', help='í†µê³„ ì •ë³´ ì¡°íšŒ')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == 'create':
            create_review(args.input, args.config, args.output)
        
        elif args.command == 'list':
            list_reviews(limit=args.limit)
        
        elif args.command == 'search':
            list_reviews(search=args.query)
        
        elif args.command == 'stats':
            show_statistics()
    
    except KeyboardInterrupt:
        logger.info("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()

