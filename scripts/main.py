"""
í‹°ìŠ¤í† ë¦¬ ìë™ í¬ìŠ¤íŒ… ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import yaml
import logging
from pathlib import Path
from typing import List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
project_root = Path(__file__).parent.parent

# src ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(project_root))

from src.api.tistory_api import TistoryAPI
from src.content.content_generator import generate_paper_review_content
from src.data.post_manager import PostManager
from src.client.claude_client import ClaudeClient
from src.data.paper_manager import PaperManager
from src.data.paper_collector import PaperCollector
from src.content.image_finder import ImageFinder, insert_images_to_content

# ì¿ í‚¤ ê°±ì‹  ëª¨ë“ˆ (ì„ íƒì )
try:
    from src.utils.cookie_refresher import CookieRefresher
    COOKIE_REFRESH_AVAILABLE = True
except ImportError:
    COOKIE_REFRESH_AVAILABLE = False

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = project_root / 'data'
log_dir.mkdir(exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'tistory_poster.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ (ì„ íƒì )
try:
    from src.utils.scheduler import RandomScheduler
    SCHEDULER_AVAILABLE = True
    logger.debug("ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except (ImportError, Exception) as e:
    SCHEDULER_AVAILABLE = False
    logger.debug(f"ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")


class TistoryAutoPoster:
    """
    í‹°ìŠ¤í† ë¦¬ ìë™ í¬ìŠ¤í„°
    
    ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ë…¼ë¬¸ì„ ì„ íƒí•˜ì—¬
    Claudeë¡œ ë¦¬ë·°ë¥¼ ìƒì„±í•˜ê³  í‹°ìŠ¤í† ë¦¬ì— ìë™ìœ¼ë¡œ í¬ìŠ¤íŒ…í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, config_path: str = None, md_only: bool = False):
        """
        ìë™ í¬ìŠ¤í„° ì´ˆê¸°í™”

        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ config.yaml)
            md_only: Trueë©´ í‹°ìŠ¤í† ë¦¬ API ì´ˆê¸°í™” ì—†ì´ MD ìƒì„±ë§Œ ê°€ëŠ¥í•œ ëª¨ë“œ
        """
        if config_path is None:
            config_path = project_root / "config.yaml"
        self.config = self._load_config(str(config_path))
        self.md_only = md_only
        self.api = None  # md_only ëª¨ë“œì—ì„œëŠ” None

        # ì¿ í‚¤ ìë™ ê°±ì‹  ì‹œë„ (ì„¤ì •ëœ ê²½ìš°, md_onlyê°€ ì•„ë‹ ë•Œë§Œ)
        if not md_only and COOKIE_REFRESH_AVAILABLE:
            browser_auth_config = self.config.get('browser_auth', {})
            if browser_auth_config.get('auto_refresh', False):
                try:
                    refresher = CookieRefresher(str(config_path))
                    if refresher.refresh_cookies_if_needed():
                        # ê°±ì‹  í›„ ì„¤ì • ë‹¤ì‹œ ë¡œë“œ
                        self.config = self._load_config(str(config_path))
                        logger.info("ì¿ í‚¤ ìë™ ê°±ì‹ ìœ¼ë¡œ ì„¤ì • íŒŒì¼ì„ ë‹¤ì‹œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    logger.warning(f"ì¿ í‚¤ ìë™ ê°±ì‹  ì‹¤íŒ¨ (ê¸°ì¡´ ì¿ í‚¤ ì‚¬ìš©): {e}")

        # í‹°ìŠ¤í† ë¦¬ API ì´ˆê¸°í™” (md_onlyê°€ ì•„ë‹ ë•Œë§Œ)
        if not md_only:
            tistory_config = self.config['tistory']

            # ì¿ í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ ID/PW ì‚¬ìš©
            blog_id = tistory_config.get('blog_id')  # ë¸”ë¡œê·¸ ID (ì„ íƒì )
            if 'cookies' in tistory_config and tistory_config['cookies']:
                self.api = TistoryAPI(
                    blog_name=tistory_config['blog_name'],
                    cookies=tistory_config['cookies'],
                    blog_id=blog_id
                )
            else:
                self.api = TistoryAPI(
                    user_id=tistory_config['user_id'],
                    user_pw=tistory_config['user_pw'],
                    blog_name=tistory_config['blog_name'],
                    blog_id=blog_id
                )

        self.post_manager = PostManager(state_file=str(project_root / "data/post_state.json"))
        self.paper_manager = PaperManager(papers_file=str(project_root / "data/papers.json"))
        self.category_id = None
        
        # Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        self.claude_client = None
        if 'claude' in self.config and self.config['claude'].get('api_key'):
            prompts_file = self.config.get('prompts_file', 'prompts.yaml')
            prompts_path = project_root / prompts_file
            self.claude_client = ClaudeClient(
                api_key=self.config['claude']['api_key'],
                model=self.config['claude'].get('model', 'claude-sonnet-4-20250514'),
                search_model=self.config['claude'].get('search_model', 'claude-3-5-haiku-20241022'),
                prompts_file=str(prompts_path)
            )
            logger.info("Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì´ë¯¸ì§€ ì°¾ê¸° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì„ íƒ)
        self.image_finder = None
        image_config = self.config.get('image_search', {})
        google_api_key = image_config.get('google_api_key')
        google_cx = image_config.get('google_cx')
        if google_api_key and google_cx:
            self.image_finder = ImageFinder(google_api_key=google_api_key, google_cx=google_cx)
            logger.info("ì´ë¯¸ì§€ ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            # API í‚¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì´ë¯¸ì§€ ì°¾ê¸° ì‹œë„ (arXiv ë“±)
            self.image_finder = ImageFinder()
            logger.info("ê¸°ë³¸ ì´ë¯¸ì§€ ì°¾ê¸° ì‚¬ìš© (arXiv ë“±)")
        
        self._init_category()
    
    def _load_config(self, config_path: str) -> dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        config_file = Path(config_path)
        if not config_file.exists():
            raise FileNotFoundError(
                f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}\n"
                f"config.yaml.exampleì„ ì°¸ê³ í•˜ì—¬ config.yamlì„ ìƒì„±í•´ì£¼ì„¸ìš”."
            )
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            logger.debug(f"Config loaded: {list(config.keys())}")
            if 'category' in config:
                logger.debug(f"Category config: {config['category']}")
            return config
    
    def _init_category(self):
        """ì¹´í…Œê³ ë¦¬ ID ì´ˆê¸°í™”"""
        category_config = self.config.get('category', {})
        logger.debug(f"ì¹´í…Œê³ ë¦¬ ì„¤ì •: {category_config}")
        category_name = category_config.get('name', 'PaperReview')
        
        # ì„¤ì • íŒŒì¼ì— ì¹´í…Œê³ ë¦¬ IDê°€ ì§ì ‘ ì§€ì •ëœ ê²½ìš° ì‚¬ìš©
        category_id = category_config.get('id')
        logger.debug(f"ì¹´í…Œê³ ë¦¬ ID (raw): {category_id}, type: {type(category_id)}")
        
        if category_id:
            self.category_id = str(category_id).strip()
            logger.info(f"ì¹´í…Œê³ ë¦¬ ID (ì„¤ì • íŒŒì¼ì—ì„œ): {self.category_id} ({category_name})")
        else:
            # ì¹´í…Œê³ ë¦¬ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
            logger.info(f"ì¹´í…Œê³ ë¦¬ IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ ì‹œë„: {category_name}")
            self.category_id = self.api.get_category_id_by_name(category_name)
            
            if self.category_id is None or self.category_id == "0":
                logger.warning(
                    f"ì¹´í…Œê³ ë¦¬ '{category_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                    f"ë¯¸ë¶„ë¥˜(0)ë¡œ ê²Œì‹œë©ë‹ˆë‹¤."
                )
                self.category_id = "0"
            else:
                logger.info(f"ì¹´í…Œê³ ë¦¬ ID: {self.category_id} ({category_name})")
    
    def _extract_abbreviation(self, paper_title: str) -> str:
        """
        ë…¼ë¬¸ ì œëª©ì—ì„œ ì•½ì–´ ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
        
        ìš°ì„ ìˆœìœ„:
        1. ì œëª©ì— ì´ë¯¸ [XXX] í˜•ì‹ì´ ìˆìœ¼ë©´ ì¶”ì¶œ
        2. ì•Œë ¤ì§„ ì•½ì–´ ì‚¬ì „ ê¸°ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­
        3. ì œëª©ì˜ ì£¼ìš” ë‹¨ì–´ ì²« ê¸€ì ì¡°í•©ìœ¼ë¡œ ì•½ì–´ ìƒì„± ì‹œë„
        """
        import re
        
        # 1. ì œëª© ì•ì— [XXX] í˜•ì‹ì´ ìˆìœ¼ë©´ ì¶”ì¶œ
        bracket_match = re.match(r'\[([^\]]+)\]\s*(.+)', paper_title)
        if bracket_match:
            return bracket_match.group(1)
        
        title_lower = paper_title.lower()
        title_words = paper_title.split()
        
        # 2. ì•Œë ¤ì§„ ì•½ì–´ ì‚¬ì „ (í‚¤ì›Œë“œ â†’ ì•½ì–´ ë§¤í•‘)
        # ë” í¬ê´„ì ì¸ í‚¤ì›Œë“œ íŒ¨í„´ ì‚¬ìš©
        abbreviation_patterns = [
            # Vision & Transformer
            (['vision transformer', 'an image is worth', 'image is worth 16x16'], 'ViT'),
            (['swin transformer'], 'Swin'),
            (['transformer', 'attention is all you need'], 'Transformer'),
            (['convnext', 'convnet for the'], 'ConvNeXt'),
            
            # Self-Supervised Learning
            (['swav', 'swapping assignments', 'contrasting cluster assignments'], 'SwAV'),
            (['simclr', 'simple framework for contrastive', 'contrastive learning'], 'SimCLR'),
            (['moco', 'momentum contrast', 'contrast for unsupervised'], 'MoCo'),
            (['byol', 'bootstrap your own', 'self-supervised'], 'BYOL'),
            (['dino', 'knowledge distillation'], 'DINO'),
            (['mae', 'masked autoencoder'], 'MAE'),
            (['beit', 'bert pre-training'], 'BEiT'),
            (['dall-e', 'dalle'], 'DALL-E'),
            
            # Multimodal
            (['clip', 'natural language supervision', 'learning transferable'], 'CLIP'),
            (['blip', 'bootstrapping language-image'], 'BLIP'),
            (['flamingo', 'few-shot learning'], 'Flamingo'),
            (['llava', 'large language and vision'], 'LLaVA'),
            
            # Object Detection & Segmentation
            (['detr', 'end-to-end object detection'], 'DETR'),
            (['yolo'], 'YOLO'),
            (['mask r-cnn', 'mask rcnn'], 'Mask R-CNN'),
            (['faster r-cnn'], 'Faster R-CNN'),
            (['retinanet'], 'RetinaNet'),
            (['segment anything', 'sam'], 'SAM'),
            (['deeplab'], 'DeepLab'),
            
            # Generative Models
            (['diffusion'], 'DDPM'),  # ê¸°ë³¸ì€ DDPM, ì•„ë˜ì—ì„œ ë” êµ¬ì²´ì ìœ¼ë¡œ í™•ì¸
            (['latent diffusion', 'ldm'], 'LDM'),
            (['stable diffusion'], 'Stable Diffusion'),
            (['gan', 'generative adversarial'], 'GAN'),
            (['stylegan'], 'StyleGAN'),
            (['pix2pix'], 'Pix2Pix'),
            (['cyclegan'], 'CycleGAN'),
            (['progressive gan'], 'Progressive GAN'),
            
            # 3D & NeRF
            (['nerf', 'neural radiance fields'], 'NeRF'),
            (['instant ngp', 'instant neural graphics'], 'Instant-NGP'),
            (['gaussian splatting', '3d gaussian'], '3D-GS'),
            
            # Language Models
            (['gpt'], 'GPT'),
            (['bert', 'bidirectional encoder'], 'BERT'),
            (['t5', 'text-to-text transfer'], 'T5'),
            (['llama'], 'LLaMA'),
            (['sora'], 'Sora'),
            
            # Efficient & Compression
            (['lora', 'low-rank adaptation'], 'LoRA'),
            (['quantization'], 'Quantization'),
            (['knowledge distillation'], 'KD'),
            (['pruning'], 'Pruning'),
            
            # Video
            (['video transformer'], 'ViViT'),
            (['timesformer'], 'TimeSformer'),
            (['videomae'], 'VideoMAE'),
            
            # Others
            (['resnet', 'residual learning'], 'ResNet'),
            (['efficientnet'], 'EfficientNet'),
            (['mobilenet'], 'MobileNet'),
            (['regnet'], 'RegNet'),
            (['vision-language'], 'VLP'),
        ]
        
        # í‚¤ì›Œë“œ íŒ¨í„´ ë§¤ì¹­
        for keywords, abbrev in abbreviation_patterns:
            for keyword in keywords:
                if keyword in title_lower:
                    return abbrev
        
        # 3. ì œëª©ì—ì„œ ì•½ì–´ ì¶”ì¶œ ì‹œë„ (ë‹¨ì–´ì˜ ì²« ê¸€ì)
        # ì£¼ìš” ë‹¨ì–´ë“¤ (ë¶ˆìš©ì–´ ì œì™¸)
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from', 'as', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they'}
        
        # ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ
        important_words = [w for w in title_words if w and w[0].isupper() and w.lower() not in stop_words]
        
        if len(important_words) >= 2:
            # ì²« 3-4ê°œ ë‹¨ì–´ì˜ ì²« ê¸€ìë¡œ ì•½ì–´ ìƒì„±
            abbrev_candidates = []
            for word in important_words[:4]:
                # ë‹¨ì–´ê°€ ì´ë¯¸ ì•½ì–´ì²˜ëŸ¼ ë³´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if len(word) <= 6 and word.isupper():
                    abbrev_candidates.append(word)
                else:
                    # ì²« ê¸€ìë§Œ
                    abbrev_candidates.append(word[0].upper())
            
            # ì•½ì–´ ìƒì„± (2-4ê¸€ì)
            if abbrev_candidates:
                abbrev = ''.join(abbrev_candidates[:4])
                # ì•½ì–´ê°€ ë„ˆë¬´ ê¸¸ë©´ 4ê¸€ìë¡œ ì œí•œ
                if len(abbrev) > 4:
                    abbrev = abbrev[:4]
                # ìµœì†Œ 2ê¸€ìëŠ” ë˜ì–´ì•¼ í•¨
                if len(abbrev) >= 2:
                    return abbrev
        
        # 4. ì²« ë‹¨ì–´ê°€ ì´ë¯¸ ì•½ì–´ì²˜ëŸ¼ ë³´ì´ë©´ ì‚¬ìš©
        if title_words:
            first_word = title_words[0]
            # ëŒ€ë¬¸ìë§Œ í¬í•¨í•˜ê³  2-6ê¸€ìë©´ ì•½ì–´ë¡œ ê°„ì£¼
            if first_word.isupper() and 2 <= len(first_word) <= 6:
                return first_word
            # ì²« ê¸€ìë“¤ì´ ëŒ€ë¬¸ìì´ê³  2-4ê¸€ìë©´ ì•½ì–´ë¡œ ê°„ì£¼ (ì˜ˆ: "GPT-4", "BERT")
            caps_only = ''.join([c for c in first_word if c.isupper()])
            if len(caps_only) >= 2 and len(caps_only) <= 4:
                return caps_only
        
        # 5. ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ì²« ë‹¨ì–´ ì‚¬ìš©
        return title_words[0] if title_words else 'Paper'
        if 'segment anything' in title_lower or 'sam' in title_lower:
            return 'SAM'
        
        # YOLO ê´€ë ¨
        if 'yolo' in title_lower:
            return 'YOLO'
        
        # EfficientNet ê´€ë ¨
        if 'efficientnet' in title_lower:
            return 'EfficientNet'
        
        # BLIP ê´€ë ¨
        if 'blip' in title_lower:
            return 'BLIP'
        
        # GPT ê´€ë ¨
        if 'gpt' in title_lower:
            return 'GPT'
        
        # Sora ê´€ë ¨
        if 'sora' in title_lower:
            return 'Sora'
        
        # ConvNeXt ê´€ë ¨
        if 'convnext' in title_lower or 'convnet for the' in title_lower:
            return 'ConvNeXt'
        
        # 3. ì—†ìœ¼ë©´ ì œëª©ì˜ ì²« ë‹¨ì–´ ì‚¬ìš© (ëŒ€ë¬¸ìë§Œ)
        first_word = paper_title.split()[0] if paper_title.split() else 'Paper'
        # ëŒ€ë¬¸ìë§Œ ì¶”ì¶œ (ì˜ˆ: "DINOv2" -> "DINO")
        caps_only = ''.join([c for c in first_word if c.isupper()])
        if caps_only:
            return caps_only
        
        return first_word
    
    def create_post(self, paper_index: int = None, save_md_only: bool = False, output_dir: str = None, progress_callback=None):
        """
        í¬ìŠ¤íŠ¸ ì‘ì„±

        Args:
            paper_index: ë°œí–‰í•  ë…¼ë¬¸ ì¸ë±ìŠ¤ (Noneì´ë©´ ìë™ ì„ íƒ)
            save_md_only: Trueë©´ ë°œí–‰í•˜ì§€ ì•Šê³  MD íŒŒì¼ë§Œ ì €ì¥
            output_dir: MD ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output/)
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜

        Returns:
            dict: {
                'success': bool,
                'paper': dict,
                'title': str,
                'content': str (ë§ˆí¬ë‹¤ìš´),
                'html_content': str,
                'url': str or None,
                'md_path': str or None
            }
        """
        def notify(msg):
            if progress_callback:
                progress_callback(msg)

        result = {
            'success': False,
            'paper': None,
            'title': None,
            'content': None,
            'html_content': None,
            'url': None,
            'md_path': None,
            'error': None
        }

        try:
            notify("ğŸ“‹ ë…¼ë¬¸ ì •ë³´ ë¡œë”© ì¤‘...")
            
            # ë…¼ë¬¸ ì„ íƒ (ì¸ë±ìŠ¤ ì§€ì • ë˜ëŠ” ìë™ ì„ íƒ)
            if paper_index is not None:
                paper = self.paper_manager.get_paper_for_post(paper_index)
            else:
                paper = self.paper_manager.get_next_paper()

            if not paper:
                logger.error("ë¦¬ë·°í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
                result['error'] = "ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                raise Exception("ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            # ì œëª© ìƒì„±: [{ì•½ì–´}] ì œëª© ì „ì²´
            paper_title = paper.get('title', 'ë…¼ë¬¸ ë¦¬ë·°')
            post_number = self.post_manager.get_next_post_number()
            abbreviation = self._extract_abbreviation(paper_title)
            title = f"[{abbreviation}] {paper_title}"
            
            logger.info(f"í¬ìŠ¤íŠ¸ ì‘ì„± ì‹œì‘: {title}")
            authors = paper.get('authors', [])
            authors_display = authors[:3] if isinstance(authors, list) else authors
            logger.info(f"ë…¼ë¬¸ ì •ë³´: {authors_display}, {paper.get('year', 'N/A')}ë…„")
            
            notify("ğŸ¤– AI ë¦¬ë·° ìƒì„± ì¤‘... (1~2ë¶„ ì†Œìš”)")
            
            # ì½˜í…ì¸  ìƒì„± (Claude ì‚¬ìš©, Scientific Skills ì§€ì›)
            review_model = self.config.get('claude', {}).get('review_model')
            scientific_config = self.config.get('scientific_skills', {})
            use_scientific = scientific_config.get('enabled', False)
            scientific_style = scientific_config.get('default_style', 'peer-review')

            content = generate_paper_review_content(
                paper=paper,
                claude_client=self.claude_client,
                review_number=post_number,
                review_model=review_model,
                use_scientific_skills=use_scientific,
                scientific_style=scientific_style
            )
            
            # ì´ë¯¸ì§€ ì°¾ê¸° ë° ì‚½ì… (ì•„í‚¤í…ì²˜ í•„ìˆ˜, ìµœëŒ€ 5ê°œ)
            image_urls_to_embed = []
            if self.image_finder:
                try:
                    notify("ğŸ–¼ï¸ ë…¼ë¬¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
                    logger.info("ë…¼ë¬¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘... (ì•„í‚¤í…ì²˜, ì‹¤í—˜ê²°ê³¼, ì§ê´€ì  ì´ë¯¸ì§€)")
                    images = self.image_finder.find_images_for_paper(
                        paper,
                        min_images=1,  # ìµœì†Œ 1ê°œ (ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€)
                        max_images=5   # ìµœëŒ€ 5ê°œ (ì•„í‚¤í…ì²˜ 1-2ê°œ, ì‹¤í—˜ê²°ê³¼ 1-2ê°œ, ì§ê´€ì  1ê°œ)
                    )
                    if images:
                        arch_count = sum(1 for img in images if img.get('type') == 'architecture')
                        exp_count = sum(1 for img in images if img.get('type') == 'experiment')
                        int_count = sum(1 for img in images if img.get('type') == 'intuitive')
                        logger.info(f"ì´ {len(images)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. (ì•„í‚¤í…ì²˜: {arch_count}, ì‹¤í—˜ê²°ê³¼: {exp_count}, ê¸°íƒ€: {int_count})")
                        content = insert_images_to_content(content, images, paper_title)
                        # ì´ë¯¸ì§€ URL ì €ì¥ (Base64 ë³€í™˜ìš©)
                        image_urls_to_embed = [img.get('url', '') for img in images if img.get('url')]
                    else:
                        logger.warning("ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê³„ì† ì§„í–‰): {e}")
            
            # ë…¼ë¬¸ ë©”íƒ€ì •ë³´ ì¶”ê°€ (ì €ìëŠ” ìµœëŒ€ 3ëª…ë§Œ í‘œì‹œ)
            authors = paper.get('authors', [])
            authors_display = ', '.join(authors[:3]) if isinstance(authors, list) else str(authors)
            if isinstance(authors, list) and len(authors) > 3:
                authors_display += f" ì™¸ {len(authors) - 3}ëª…"
            
            meta_info = f"""# {paper_title}

**ì €ì**: {authors_display}  
**ë°œí–‰ë…„ë„**: {paper.get('year', 'N/A')}ë…„  
**ì¸ìš©ìˆ˜**: {paper.get('citations', 'N/A')}íšŒ  
"""
            if paper.get('url'):
                meta_info += f"**ë…¼ë¬¸ ë§í¬**: [{paper.get('url')}]({paper.get('url')})  \n"
            if paper.get('arxiv_id'):
                meta_info += f"**arXiv ID**: {paper.get('arxiv_id')}  \n"
            
            meta_info += "\n---\n\n"
            full_content = meta_info + content

            # ê²°ê³¼ ì €ì¥
            result['paper'] = paper
            result['title'] = title
            result['content'] = full_content

            notify("ğŸ’¾ ë§ˆí¬ë‹¤ìš´ ì €ì¥ ì¤‘...")
            
            # MD ì €ì¥ (ìš”ì²­ëœ ê²½ìš° ë˜ëŠ” í•­ìƒ ë°±ì—…)
            if output_dir is None:
                output_dir = str(project_root / "output")
            Path(output_dir).mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ëª… ìƒì„± (ì•ˆì „í•œ ë¬¸ìë§Œ ì‚¬ìš©)
            safe_title = "".join(c for c in paper_title if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
            md_filename = f"{safe_title}_{paper.get('year', 'unknown')}.md"
            md_path = Path(output_dir) / md_filename

            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(full_content)
            result['md_path'] = str(md_path)
            logger.info(f"ë§ˆí¬ë‹¤ìš´ ì €ì¥: {md_path}")

            # MDë§Œ ì €ì¥í•˜ëŠ” ê²½ìš° ì—¬ê¸°ì„œ ë°˜í™˜
            if save_md_only:
                result['success'] = True
                notify("âœ… ë§ˆí¬ë‹¤ìš´ ì €ì¥ ì™„ë£Œ!")
                logger.info(f"ë§ˆí¬ë‹¤ìš´ë§Œ ì €ì¥ ì™„ë£Œ: {title}")
                return result

            notify("ğŸ“ HTML ë³€í™˜ ì¤‘...")
            
            # HTMLë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ â†’ HTML)
            html_content = self._markdown_to_html(full_content, image_urls_to_embed)
            result['html_content'] = html_content

            notify("ğŸŒ í‹°ìŠ¤í† ë¦¬ ë°œí–‰ ì¤‘...")
            
            # í‹°ìŠ¤í† ë¦¬ì— ê¸€ ì‘ì„±
            api_result = self.api.write_post(
                title=title,
                content=html_content,
                category_id=self.category_id
            )

            # ë…¼ë¬¸ ë¦¬ë·° ì™„ë£Œ í‘œì‹œ
            self.paper_manager.mark_paper_reviewed(paper)

            result['success'] = True
            result['url'] = api_result.get('url')

            notify("âœ… ë°œí–‰ ì™„ë£Œ!")
            logger.info(f"í¬ìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ: {title}")
            logger.info(f"í¬ìŠ¤íŠ¸ URL: {result['url']}")

            # ì§„í–‰ ìƒí™© ìƒì„¸ ì •ë³´ ë¡œê¹…
            progress_info = self.paper_manager.get_progress_info()
            logger.info(f"ì§„í–‰ ìƒí™©: {progress_info['reviewed_count']}/{progress_info['total_papers']} ë…¼ë¬¸ ë¦¬ë·° ì™„ë£Œ ({progress_info['progress_percent']}%)")
            logger.info(f"í˜„ì¬ ì¸ë±ìŠ¤: {progress_info['current_index']}, ë‚¨ì€ ë…¼ë¬¸: {progress_info['remaining_count']}ê°œ")

            return result

        except Exception as e:
            logger.error(f"í¬ìŠ¤íŠ¸ ì‘ì„± ì‹¤íŒ¨: {e}", exc_info=True)
            result['error'] = str(e)
            # MDê°€ ì´ë¯¸ ì €ì¥ë˜ì—ˆë‹¤ë©´ ê²½ë¡œ ìœ ì§€
            return result

    def create_post_from_paper(self, paper: Dict, save_md_only: bool = False, output_dir: str = None, progress_callback=None):
        """
        ì™¸ë¶€ ë…¼ë¬¸ ì •ë³´ë¥¼ ë°›ì•„ì„œ í¬ìŠ¤íŠ¸ ì‘ì„± (ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ë…¼ë¬¸ìš©)

        Args:
            paper: ë…¼ë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (title, authors, year, citations, url, abstract ë“±)
            save_md_only: Trueë©´ ë°œí–‰í•˜ì§€ ì•Šê³  MD íŒŒì¼ë§Œ ì €ì¥
            output_dir: MD ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output/)
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜

        Returns:
            dict: create_postì™€ ë™ì¼í•œ í˜•ì‹
        """
        def notify(msg):
            if progress_callback:
                progress_callback(msg)

        result = {
            'success': False,
            'paper': None,
            'title': None,
            'content': None,
            'html_content': None,
            'url': None,
            'md_path': None,
            'error': None
        }

        try:
            notify("ğŸ“‹ ë…¼ë¬¸ ì •ë³´ í™•ì¸ ì¤‘...")
            
            if not paper or not paper.get('title'):
                result['error'] = "ë…¼ë¬¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
                raise Exception("ë…¼ë¬¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ì œëª© ìƒì„±: [{ì•½ì–´}] ì œëª© ì „ì²´
            paper_title = paper.get('title', 'ë…¼ë¬¸ ë¦¬ë·°')
            post_number = self.post_manager.get_next_post_number()
            abbreviation = self._extract_abbreviation(paper_title)
            title = f"[{abbreviation}] {paper_title}"

            logger.info(f"ì™¸ë¶€ ë…¼ë¬¸ í¬ìŠ¤íŠ¸ ì‘ì„± ì‹œì‘: {title}")
            authors = paper.get('authors', [])
            authors_display = authors[:3] if isinstance(authors, list) else authors
            logger.info(f"ë…¼ë¬¸ ì •ë³´: {authors_display}, {paper.get('year', 'N/A')}ë…„")

            notify("ğŸ¤– AI ë¦¬ë·° ìƒì„± ì¤‘... (1~2ë¶„ ì†Œìš”)")
            
            # ì½˜í…ì¸  ìƒì„± (Claude ì‚¬ìš©, Scientific Skills ì§€ì›)
            review_model = self.config.get('claude', {}).get('review_model')
            scientific_config = self.config.get('scientific_skills', {})
            use_scientific = scientific_config.get('enabled', False)
            scientific_style = scientific_config.get('default_style', 'peer-review')

            content = generate_paper_review_content(
                paper=paper,
                claude_client=self.claude_client,
                review_number=post_number,
                review_model=review_model,
                use_scientific_skills=use_scientific,
                scientific_style=scientific_style
            )

            # ì´ë¯¸ì§€ ì°¾ê¸° ë° ì‚½ì…
            image_urls_to_embed = []
            if self.image_finder:
                try:
                    notify("ğŸ–¼ï¸ ë…¼ë¬¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
                    logger.info("ë…¼ë¬¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
                    images = self.image_finder.find_images_for_paper(
                        paper,
                        min_images=1,
                        max_images=5
                    )
                    if images:
                        logger.info(f"ì´ {len(images)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        content = insert_images_to_content(content, images, paper_title)
                        image_urls_to_embed = [img.get('url', '') for img in images if img.get('url')]
                    else:
                        logger.warning("ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê³„ì† ì§„í–‰): {e}")

            # ë…¼ë¬¸ ë©”íƒ€ì •ë³´ ì¶”ê°€
            authors = paper.get('authors', [])
            authors_display = ', '.join(authors[:3]) if isinstance(authors, list) else str(authors)
            if isinstance(authors, list) and len(authors) > 3:
                authors_display += f" ì™¸ {len(authors) - 3}ëª…"

            meta_info = f"""# {paper_title}

**ì €ì**: {authors_display}
**ë°œí–‰ë…„ë„**: {paper.get('year', 'N/A')}ë…„
**ì¸ìš©ìˆ˜**: {paper.get('citations', 'N/A')}íšŒ
"""
            if paper.get('url'):
                meta_info += f"**ë…¼ë¬¸ ë§í¬**: [{paper.get('url')}]({paper.get('url')})  \n"
            if paper.get('arxiv_id'):
                meta_info += f"**arXiv ID**: {paper.get('arxiv_id')}  \n"

            meta_info += "\n---\n\n"
            full_content = meta_info + content

            # ê²°ê³¼ ì €ì¥
            result['paper'] = paper
            result['title'] = title
            result['content'] = full_content

            notify("ğŸ’¾ ë§ˆí¬ë‹¤ìš´ ì €ì¥ ì¤‘...")
            
            # MD ì €ì¥
            if output_dir is None:
                output_dir = str(project_root / "output")
            Path(output_dir).mkdir(parents=True, exist_ok=True)

            safe_title = "".join(c for c in paper_title if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
            md_filename = f"{safe_title}_{paper.get('year', 'unknown')}.md"
            md_path = Path(output_dir) / md_filename

            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(full_content)
            result['md_path'] = str(md_path)
            logger.info(f"ë§ˆí¬ë‹¤ìš´ ì €ì¥: {md_path}")

            # MDë§Œ ì €ì¥í•˜ëŠ” ê²½ìš° ì—¬ê¸°ì„œ ë°˜í™˜
            if save_md_only:
                result['success'] = True
                notify("âœ… ë§ˆí¬ë‹¤ìš´ ì €ì¥ ì™„ë£Œ!")
                logger.info(f"ë§ˆí¬ë‹¤ìš´ë§Œ ì €ì¥ ì™„ë£Œ: {title}")
                return result

            notify("ğŸ“ HTML ë³€í™˜ ì¤‘...")
            
            # HTMLë¡œ ë³€í™˜
            html_content = self._markdown_to_html(full_content, image_urls_to_embed)
            result['html_content'] = html_content

            notify("ğŸŒ í‹°ìŠ¤í† ë¦¬ ë°œí–‰ ì¤‘...")
            
            # í‹°ìŠ¤í† ë¦¬ì— ê¸€ ì‘ì„±
            api_result = self.api.write_post(
                title=title,
                content=html_content,
                category_id=self.category_id
            )

            result['success'] = True
            result['url'] = api_result.get('url')

            notify("âœ… ë°œí–‰ ì™„ë£Œ!")
            logger.info(f"ì™¸ë¶€ ë…¼ë¬¸ í¬ìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ: {title}")
            logger.info(f"í¬ìŠ¤íŠ¸ URL: {result['url']}")

            return result

        except Exception as e:
            logger.error(f"ì™¸ë¶€ ë…¼ë¬¸ í¬ìŠ¤íŠ¸ ì‘ì„± ì‹¤íŒ¨: {e}", exc_info=True)
            result['error'] = str(e)
            return result

    def search_paper_info(self, paper_title: str) -> Dict:
        """
        ë…¼ë¬¸ ì œëª©ìœ¼ë¡œ ìƒì„¸ ì •ë³´ ê²€ìƒ‰

        Args:
            paper_title: ê²€ìƒ‰í•  ë…¼ë¬¸ ì œëª©

        Returns:
            ë…¼ë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬)
        """
        try:
            papers = self.claude_client.generate_paper_details([paper_title])
            if papers and len(papers) > 0:
                return papers[0]
            return {}
        except Exception as e:
            logger.error(f"ë…¼ë¬¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {}

    def search_latest_papers_by_category(self, category: str, keywords: List[str], count: int = 5) -> List[Dict]:
        """
        ë¶„ì•¼ë³„ ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰

        Args:
            category: ë¶„ì•¼ëª… (ì˜ˆ: "Computer Vision", "NLP & Language Models")
            keywords: í•´ë‹¹ ë¶„ì•¼ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            count: ê²€ìƒ‰í•  ë…¼ë¬¸ ê°œìˆ˜

        Returns:
            ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            keyword_str = ", ".join(keywords[:5])  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
            search_query = f"latest {category} AI papers 2024 2025 {keyword_str}"

            logger.info(f"ë¶„ì•¼ë³„ ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰: {category}")
            papers = self.claude_client.generate_paper_details([search_query], is_category_search=True, count=count)

            if papers:
                # ê° ë…¼ë¬¸ì— ë¶„ì•¼ ì •ë³´ ì¶”ê°€
                for paper in papers:
                    paper['searched_category'] = category
                return papers
            return []
        except Exception as e:
            logger.error(f"ë¶„ì•¼ë³„ ë…¼ë¬¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _markdown_to_html(self, markdown: str, image_urls: List[str] = None) -> str:
        """
        ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜
        
        Args:
            markdown: ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´
            image_urls: Base64ë¡œ ë³€í™˜í•  ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
        """
        import re
        import base64
        import requests
        from typing import Optional
        from urllib.parse import urlparse, urlunparse
        
        if image_urls is None:
            image_urls = []
        
        def normalize_url(url: str) -> str:
            """URL ì •ê·œí™” (í”„ë¡œí† ì½œ, www ë“±)"""
            if not url:
                return url
            # ì´ë¯¸ data URLì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if url.startswith('data:'):
                return url
            # í”„ë¡œí† ì½œì´ ì—†ìœ¼ë©´ https ì¶”ê°€
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            return url
        
        def download_image_to_base64(url: str, max_size_mb: float = 5.0) -> Optional[str]:
            """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° Base64 ë³€í™˜ (ì¬ì‹œë„ í¬í•¨)"""
            normalized_url = normalize_url(url)
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Referer': 'https://www.google.com/'
            }
            
            # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
            for attempt in range(3):
                try:
                    response = requests.get(
                        normalized_url, 
                        timeout=15, 
                        headers=headers,
                        allow_redirects=True,
                        stream=True  # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì•„ì„œ í¬ê¸° í™•ì¸
                    )
                    
                    if response.status_code == 200:
                        # Content-Type í™•ì¸
                        content_type = response.headers.get('Content-Type', '').split(';')[0].strip()
                        
                        # ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ê²½ìš°ë„ ì‹œë„ (ì¼ë¶€ ì„œë²„ê°€ Content-Typeì„ ì˜ëª» ì„¤ì •)
                        # Content-Length í™•ì¸ (ë„ˆë¬´ í° ì´ë¯¸ì§€ëŠ” ì œì™¸)
                        content_length = response.headers.get('Content-Length')
                        if content_length:
                            size_mb = int(content_length) / (1024 * 1024)
                            if size_mb > max_size_mb:
                                logger.warning(f"ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¼ ({size_mb:.2f}MB > {max_size_mb}MB): {normalized_url[:60]}...")
                                # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì•„ì„œ ì²˜ë¦¬
                                content = b''
                                for chunk in response.iter_content(chunk_size=8192):
                                    content += chunk
                                    if len(content) > max_size_mb * 1024 * 1024:
                                        logger.warning(f"ì´ë¯¸ì§€ í¬ê¸° ì œí•œ ì´ˆê³¼, ì¤‘ë‹¨: {normalized_url[:60]}...")
                                        return None
                            else:
                                content = response.content
                        else:
                            # Content-Lengthê°€ ì—†ìœ¼ë©´ ì „ì²´ ë°›ê¸° (í•˜ì§€ë§Œ í¬ê¸° ì œí•œ)
                            content = b''
                            for chunk in response.iter_content(chunk_size=8192):
                                content += chunk
                                if len(content) > max_size_mb * 1024 * 1024:
                                    logger.warning(f"ì´ë¯¸ì§€ í¬ê¸° ì œí•œ ì´ˆê³¼: {normalized_url[:60]}...")
                                    return None
                        
                        if not content:
                            logger.warning(f"ì´ë¯¸ì§€ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {normalized_url[:60]}...")
                            return None
                        
                        # Content-Typeì´ ì—†ê±°ë‚˜ ì´ë¯¸ì§€ê°€ ì•„ë‹ˆì–´ë„ ì‹œë„
                        if not content_type or content_type not in ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp', 'image/svg+xml']:
                            # Content-Typeì„ íŒŒì¼ í™•ì¥ìë‚˜ ë‚´ìš©ìœ¼ë¡œ ì¶”ë¡ 
                            if normalized_url.lower().endswith(('.jpg', '.jpeg')):
                                content_type = 'image/jpeg'
                            elif normalized_url.lower().endswith('.png'):
                                content_type = 'image/png'
                            elif normalized_url.lower().endswith('.gif'):
                                content_type = 'image/gif'
                            elif normalized_url.lower().endswith('.webp'):
                                content_type = 'image/webp'
                            elif normalized_url.lower().endswith('.svg'):
                                content_type = 'image/svg+xml'
                            else:
                                # íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ í™•ì¸
                                if content.startswith(b'\xff\xd8\xff'):
                                    content_type = 'image/jpeg'
                                elif content.startswith(b'\x89PNG'):
                                    content_type = 'image/png'
                                elif content.startswith(b'GIF'):
                                    content_type = 'image/gif'
                                elif content.startswith(b'RIFF') and b'WEBP' in content[:20]:
                                    content_type = 'image/webp'
                                else:
                                    content_type = 'image/png'  # ê¸°ë³¸ê°’
                        
                        # Base64 ì¸ì½”ë”©
                        img_base64 = base64.b64encode(content).decode('utf-8')
                        data_url = f"data:{content_type};base64,{img_base64}"
                        
                        logger.info(f"ì´ë¯¸ì§€ Base64 ë³€í™˜ ì„±ê³µ ({len(content) / 1024:.1f}KB): {normalized_url[:60]}...")
                        return data_url
                    else:
                        logger.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code}): {normalized_url[:60]}...")
                        
                except requests.exceptions.Timeout:
                    logger.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/3): {normalized_url[:60]}...")
                    if attempt < 2:
                        continue
                except requests.exceptions.RequestException as e:
                    logger.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/3): {e} - {normalized_url[:60]}...")
                    if attempt < 2:
                        continue
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ (ì‹œë„ {attempt + 1}/3): {e} - {normalized_url[:60]}...")
                    if attempt < 2:
                        continue
            
            return None
        
        # ì´ë¯¸ì§€ URLì„ Base64ë¡œ ë³€í™˜ (ìºì‹œ)
        image_base64_cache = {}
        
        # ëª¨ë“  ì´ë¯¸ì§€ URLì„ Base64ë¡œ ë³€í™˜ ì‹œë„
        for img_url in image_urls:
            if not img_url:
                continue
            
            # ì´ë¯¸ data URLì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if img_url.startswith('data:'):
                image_base64_cache[img_url] = img_url
                continue
            
            # ìºì‹œì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ì‹œë„
            if img_url not in image_base64_cache:
                base64_data = download_image_to_base64(img_url)
                if base64_data:
                    image_base64_cache[img_url] = base64_data
                    # ì •ê·œí™”ëœ URLë„ ìºì‹œì— ì¶”ê°€ (ë§ˆí¬ë‹¤ìš´ê³¼ HTMLì—ì„œ URLì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                    normalized = normalize_url(img_url)
                    if normalized != img_url:
                        image_base64_cache[normalized] = base64_data
                else:
                    # ë³€í™˜ ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ URL ì‚¬ìš© (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
                    logger.warning(f"ì´ë¯¸ì§€ Base64 ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ URL ì‚¬ìš©: {img_url[:60]}...")
                    image_base64_cache[img_url] = normalize_url(img_url)
        
        lines = markdown.split('\n')
        result = []
        in_list = False
        list_type = None
        in_code = False
        code_lines = []
        
        i = 0
        while i < len(lines):
            line = lines[i]
            stripped = line.strip()
            
            # ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬
            if stripped.startswith('```'):
                if in_code:
                    # ì½”ë“œ ë¸”ë¡ ì¢…ë£Œ
                    result.append(f"<pre><code>{'<br>'.join(code_lines)}</code></pre>")
                    code_lines = []
                    in_code = False
                else:
                    # ì½”ë“œ ë¸”ë¡ ì‹œì‘
                    in_code = True
                    if in_list:
                        result.append(f'</{list_type}>')
                        in_list = False
                i += 1
                continue
            
            if in_code:
                code_lines.append(line)
                i += 1
                continue
            
            # ì œëª© ì²˜ë¦¬
            if stripped.startswith('### '):
                if in_list:
                    result.append(f'</{list_type}>')
                    in_list = False
                result.append(f'<h3>{stripped[4:]}</h3>')
                i += 1
                continue
            elif stripped.startswith('## '):
                if in_list:
                    result.append(f'</{list_type}>')
                    in_list = False
                result.append(f'<h2>{stripped[3:]}</h2>')
                i += 1
                continue
            elif stripped.startswith('# '):
                if in_list:
                    result.append(f'</{list_type}>')
                    in_list = False
                result.append(f'<h1>{stripped[2:]}</h1>')
                i += 1
                continue
            
            # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
            if stripped.startswith('- '):
                if not in_list or list_type != 'ul':
                    if in_list:
                        result.append(f'</{list_type}>')
                    result.append('<ul>')
                    in_list = True
                    list_type = 'ul'
                content = stripped[2:]
                # ê°•ì¡° ì²˜ë¦¬
                content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
                content = re.sub(r'\*(.*?)\*', r'<em>\1</em>', content)
                result.append(f'<li>{content}</li>')
            elif re.match(r'^\d+\.\s', stripped):
                if not in_list or list_type != 'ol':
                    if in_list:
                        result.append(f'</{list_type}>')
                    result.append('<ol>')
                    in_list = True
                    list_type = 'ol'
                content = re.sub(r'^\d+\.\s', '', stripped)
                # ê°•ì¡° ì²˜ë¦¬
                content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
                content = re.sub(r'\*(.*?)\*', r'<em>\1</em>', content)
                result.append(f'<li>{content}</li>')
            else:
                if in_list:
                    result.append(f'</{list_type}>')
                    in_list = False
                    list_type = None
                
                if stripped:
                    # ì´ë¯¸ì§€ ì²˜ë¦¬ (![alt](url) í˜•ì‹, ë³„ë„ ì¤„)
                    img_match = re.match(r'^!\[([^\]]*)\]\(([^\)]+)\)\s*$', stripped)
                    if img_match:
                        alt_text = img_match.group(1)
                        img_url = img_match.group(2)
                        
                        # Base64ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì •ê·œí™”ëœ URL ì‚¬ìš©
                        img_src = image_base64_cache.get(img_url)
                        if not img_src:
                            # ì •ê·œí™”ëœ URLë¡œë„ ì‹œë„
                            normalized_url = normalize_url(img_url)
                            img_src = image_base64_cache.get(normalized_url, normalized_url)
                        
                        # ì´ë¯¸ì§€ íƒœê·¸ ìƒì„± (ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€, Base64 ë˜ëŠ” URL ëª¨ë‘ ì§€ì›)
                        # Base64ê°€ ì•„ë‹ˆê³  http(s)ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ ì •ê·œí™”
                        if not img_src.startswith(('data:', 'http://', 'https://')):
                            img_src = normalize_url(img_src)
                        
                        img_tag = f'<p><img src="{img_src}" alt="{alt_text}" style="max-width: 100%; height: auto; display: block; margin: 0 auto;" onerror="this.style.display=\'none\';" /></p>'
                        result.append(img_tag)
                    else:
                        # ê°•ì¡° ì²˜ë¦¬
                        content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', line)
                        content = re.sub(r'(?<!\*)\*(?!\*)(.*?)(?<!\*)\*(?!\*)', r'<em>\1</em>', content)
                        # ë§í¬ ì²˜ë¦¬
                        content = re.sub(r'\[([^\]]+)\]\(([^\)]+)\)', r'<a href="\2">\1</a>', content)
                        result.append(f'<p>{content}</p>')
                else:
                    result.append('<br>')
            
            i += 1
        
        if in_list:
            result.append(f'</{list_type}>')
        if in_code:
            result.append(f"<pre><code>{'<br>'.join(code_lines)}</code></pre>")
        
        return '\n'.join(result)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        poster = TistoryAutoPoster()
        schedule_config = poster.config.get('schedule', {})
        scheduler_enabled = schedule_config.get('enabled', False)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œ
        if scheduler_enabled and SCHEDULER_AVAILABLE:
            logger.info("=" * 60)
            logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œ: ë§¤ì¼ ìë™ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.")
            logger.info(f"ì‹¤í–‰ ì‹œê°„ëŒ€: {schedule_config.get('start_hour', 18)}ì‹œ ~ {schedule_config.get('end_hour', 23)}ì‹œ {schedule_config.get('end_minute', 59)}ë¶„ ì‚¬ì´ ëœë¤")
            logger.info("ìˆ˜ë™ ì‹¤í–‰ì„ ì›í•˜ë©´ config.yamlì—ì„œ schedule.enabledë¥¼ falseë¡œ ë³€ê²½í•˜ì„¸ìš”.")
            logger.info("=" * 60)
            scheduler = RandomScheduler(
                start_hour=schedule_config.get('start_hour', 18),
                end_hour=schedule_config.get('end_hour', 23),
                end_minute=schedule_config.get('end_minute', 59)
            )
            scheduler.schedule_daily_random(poster.create_post)
        elif scheduler_enabled and not SCHEDULER_AVAILABLE:
            logger.warning("ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í–ˆì§€ë§Œ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì‹¤í–‰ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            logger.info("í¬ìŠ¤íŠ¸ ì‘ì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            poster.create_post()
            logger.info("í¬ìŠ¤íŠ¸ ì‘ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            # ì¦‰ì‹œ ì‹¤í–‰ ëª¨ë“œ (ê¸°ë³¸ê°’)
            logger.info("ì¦‰ì‹œ ì‹¤í–‰ ëª¨ë“œ: í¬ìŠ¤íŠ¸ ì‘ì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            poster.create_post()
            logger.info("í¬ìŠ¤íŠ¸ ì‘ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except KeyboardInterrupt:
        logger.info("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)


if __name__ == "__main__":
    main()

